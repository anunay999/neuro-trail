# -----------------------------
# Neo4j Configuration
# -----------------------------
# NEO4J_URI: The Bolt protocol URI for your Neo4j instance.
NEO4J_URI=bolt://neo4j:7687
# NEO4J_USER: The username for the Neo4j database.
NEO4J_USER=neo4j
# NEO4J_PASSWORD: The password for the Neo4j database.
NEO4J_PASSWORD=password

# -----------------------------
# Qdrant Vector Store Configuration
# -----------------------------
# VECTOR_STORE_PROVIDER: The name of the vector store provider (e.g., qdrant, pinecone, weaviate).
VECTOR_STORE_PROVIDER=qdrant
# VECTOR_STORE_KNOWLEDGE_COLLECTION: The name of the knowledge collection (or index) within the vector store.
VECTOR_STORE_KNOWLEDGE_COLLECTION=knowledge
# VECTOR_STORE_USER_COLLECTION: The name of the knowledge collection (or index) within the vector store.
VECTOR_STORE_USER_COLLECTION=user
# VECTOR_STORE_HOST: The host/IP address where the vector store is running.
VECTOR_STORE_HOST=localhost
# VECTOR_STORE_PORT: The port the vector store is listening on.
VECTOR_STORE_PORT=6333
# VECTOR_STORE_EMBEDDING_MODEL_DIMS: The dimensionality of embeddings in the vector store.
VECTOR_STORE_EMBEDDING_MODEL_DIMS=768

# -----------------------------
# LLM Configuration
# -----------------------------
# LLM_PROVIDER: The Large Language Model provider (e.g., ollama, openai, huggingface).
LLM_PROVIDER=ollama
# LLM_MODEL: The specific model or version tag to use.
LLM_MODEL=llama3.1:latest
# LLM_TEMPERATURE: The "creativity" setting for text generation (0 = deterministic).
LLM_TEMPERATURE=0
# LLM_MAX_TOKENS: The maximum number of tokens to generate in a single response.
LLM_MAX_TOKENS=2000
# LLM_OLLAMA_BASE_URL: The base URL for Ollama’s LLM API endpoint.
LLM_OLLAMA_BASE_URL=http://localhost:11434

# -----------------------------
# Embedding Model Configuration
# -----------------------------
# EMBEDDER_PROVIDER: The provider for text embeddings (e.g., ollama, openai).
EMBEDDER_PROVIDER=ollama
# EMBEDDER_MODEL: The specific embedding model or version tag to use.
EMBEDDER_MODEL=nomic-embed-text:latest
# EMBEDDER_OLLAMA_BASE_URL: The base URL for Ollama’s embedding API endpoint.
EMBEDDER_OLLAMA_BASE_URL=http://localhost:11434
